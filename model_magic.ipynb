{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_magic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Hoiy/kaggle-santander-value-prediction-challenge/blob/master/model_magic.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "VM9hmU5d-cKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cedd3723-6129-4d8a-c59b-4cb686c3be2d"
      },
      "cell_type": "code",
      "source": [
        "import dotenv\n",
        "import os\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize, minmax_scale\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from tqdm import tqdm\n",
        "\n",
        "dotenv.load_dotenv('.env')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "e0I97LtWBSrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "db2377c5-5458-4778-c665-47655e2bb03c"
      },
      "cell_type": "code",
      "source": [
        "!mkdir prep\n",
        "!gsutil rsync gs://{os.environ['GCP_BUCKET']}/prep prep"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building synchronization state...\n",
            "Starting synchronization...\n",
            "Copying gs://kaggle-195720-santander-value-prediction-challenge/prep/test.csv...\n",
            "Copying gs://kaggle-195720-santander-value-prediction-challenge/prep/test.csv.gz...\n",
            "Copying gs://kaggle-195720-santander-value-prediction-challenge/prep/test_log_feats.snappy.parquet...\n",
            "Copying gs://kaggle-195720-santander-value-prediction-challenge/prep/test_log_stats.snappy.parquet...\n",
            "\n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m -o ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://kaggle-195720-santander-value-prediction-challenge/prep/test_raw_feats.snappy.parquet...\n",
            "Copying gs://kaggle-195720-santander-value-prediction-challenge/prep/train.csv...\n",
            "Copying gs://kaggle-195720-santander-value-prediction-challenge/prep/train.csv.gz...\n",
            "Copying gs://kaggle-195720-santander-value-prediction-challenge/prep/train_log_feats.snappy.parquet...\n",
            "Copying gs://kaggle-195720-santander-value-prediction-challenge/prep/train_log_stats.snappy.parquet...\n",
            "Copying gs://kaggle-195720-santander-value-prediction-challenge/prep/train_log_target.snappy.parquet...\n",
            "Copying gs://kaggle-195720-santander-value-prediction-challenge/prep/train_raw_feats.snappy.parquet...\n",
            "Copying gs://kaggle-195720-santander-value-prediction-challenge/prep/train_target.snappy.parquet...\n",
            "- [12 files][  1.1 GiB/  1.1 GiB]    4.0 MiB/s                                  \n",
            "Operation completed over 12 objects/1.1 GiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qAtx7NRomVGl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_raw_feats = pd.read_parquet('./prep/test_raw_feats.snappy.parquet')\n",
        "df = test_raw_feats\n",
        "\n",
        "MAGIC_COLS = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1',\n",
        "  '15ace8c9f', 'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9',\n",
        "  'd6bb78916', 'b43a7cfd5', '58232a6fb', '1702b5bf0', '324921c7b', \n",
        "  '62e59a501', '2ec5b290f', '241f0f867', 'fb49e4212',  '66ace2992',\n",
        "  'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7', '1931ccfdd', \n",
        "  '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a',\n",
        "  '6619d81fc', '1db387535', 'fc99f9426', '91f701ba2',  '0572565c2',\n",
        "  '190db8488',  'adb64ff71', 'c47340d97', 'c5a231d81', '0ff32eb98'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDrcrp9YAv--",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def count_vectorize(row_vecs):\n",
        "  return pd.DataFrame([row_vecs.loc[row].value_counts() for row in row_vecs.index]).fillna(0)\n",
        "\n",
        "# def cols_count_vectorize(df):\n",
        "#   return \n",
        "\n",
        "# def rows_count_vectorize(df):\n",
        "#   return cols_count_vectorize(df.T)\n",
        "\n",
        "def dist(s1, s2):\n",
        "  return sum(np.abs(s1-s2))\n",
        "\n",
        "def col_metrics(cols, metric_func):\n",
        "  return pd.DataFrame([[metric_func(cols[i], cols[j]) for i in cols] for j in cols], columns=cols.columns, index=cols.columns)\n",
        "\n",
        "def row_metrics(rows, metric_func):\n",
        "  return col_metrics(rows.T, metric_func)\n",
        "\n",
        "def cloest_vec(row_vecs, vec, cutoff=0, metric_func=lambda x, y: sum((x-y)**2)):\n",
        "  return row_vecs.apply(lambda x: metric_func(x, vec), axis=1)\n",
        "\n",
        "def visualize_col(df, **kwargs):\n",
        "  col_enc = cols_count_vectorize(df)\n",
        "  col_enc = col_enc.drop(columns=[filled_value, 0])\n",
        "  col_enc = col_enc / col_enc.max()\n",
        "  \n",
        "  tsne = TSNE(n_components=2, verbose=1)\n",
        "  tsne_result = pd.DataFrame(tsne.fit_transform(col_enc), index=col_enc.index)\n",
        "  \n",
        "  dbscan = DBSCAN(**kwargs)\n",
        "  dbscan_result = pd.Series(dbscan.fit_predict(tsne_result), index=tsne_result.index)\n",
        "  \n",
        "  ax = tsne_result.plot.scatter(x=0, y=1, alpha=0.8, figsize=(15, 10), color=dbscan_result, cmap='tab20')\n",
        "  for x, y, s in zip(tsne_result[0], tsne_result[1], tsne_result.index):\n",
        "    ax.annotate(xy=(x,y), s=s) \n",
        "  return tsne_result\n",
        "\n",
        "def pca(row_vecs):\n",
        "  from sklearn.decomposition import PCA\n",
        "  \n",
        "  print('pca...')\n",
        "  pca = PCA(n_components=32)\n",
        "  return pd.DataFrame(pca.fit_transform(row_vecs), index=row_vecs.index)\n",
        "  \n",
        "\n",
        "def tsne(row_vecs, **kwargs):\n",
        "  from sklearn.manifold import TSNE\n",
        "  print('tsne...')\n",
        "        \n",
        "  tsne = TSNE(n_components=2, verbose=1, **kwargs)\n",
        "  return pd.DataFrame(tsne.fit_transform(row_vecs), index=row_vecs.index)\n",
        "\n",
        "def taxicab_dist(x, y):\n",
        "  return np.sum(np.abs(x-y))\n",
        "\n",
        "def shift_dist(x, y):\n",
        "  return np.sum(x.shift() != y)\n",
        "\n",
        "def dbscan(row_vecs, **kwargs):\n",
        "  from sklearn.cluster import DBSCAN\n",
        "  \n",
        "  print('dbscan...')\n",
        "  dbscan = DBSCAN(eps=5, **kwargs)\n",
        "  return pd.Series(dbscan.fit_predict(row_vecs), index=row_vecs.index)\n",
        "\n",
        "\n",
        "def plot_cluster(tsne_result, dbscan_result, labels=[]):\n",
        "  ax = tsne_result.plot.scatter(x=0, y=1, alpha=0.5, figsize=(15, 10), color=dbscan_result, cmap='tab20')\n",
        "  for l in labels:\n",
        "    ax.plot(tsne_result.loc[l][0], tsne_result.loc[l][1], 'ro')\n",
        "    ax.annotate(xy=tsne_result.loc[l], s=l)\n",
        "\n",
        "    \n",
        "def search_next_row(rows, row, period=1):\n",
        "  row = row.shift(period)\n",
        "  dist = (~rows.eq(row)).sum(axis=1)\n",
        "  indices = dist[dist==np.abs(period)].index\n",
        "  if len(indices) == 1:\n",
        "    return indices[0]\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "  \n",
        "def find_ordered_index(df, seed_index, max_period=5):\n",
        "  ordered_index = [seed_index]\n",
        "  lag = [0]\n",
        "\n",
        "  while True:\n",
        "    clean_df = df.drop(ordered_index)\n",
        "    \n",
        "    period = 0\n",
        "    while True:\n",
        "      period = period + 1\n",
        "      index = search_next_row(clean_df, df.loc[ordered_index[-1]], period)\n",
        "      if index or period == max_period:\n",
        "        break\n",
        "    \n",
        "    if not index:\n",
        "      break\n",
        "      \n",
        "    ordered_index.append(index)\n",
        "    lag.append(period)\n",
        "\n",
        "    \n",
        "  while True:\n",
        "    clean_df = df.drop(ordered_index)\n",
        "    \n",
        "    period = 0\n",
        "    while True:\n",
        "      period = period - 1\n",
        "      index = search_next_row(clean_df, df.loc[ordered_index[0]], period)\n",
        "      if index or period == -max_period:\n",
        "        break\n",
        "    \n",
        "    if not index:\n",
        "      break\n",
        "    \n",
        "    lag = [0] + [-period] + lag[1:]\n",
        "    ordered_index = [index] + ordered_index\n",
        "      \n",
        "  return ordered_index, lag\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ECodEIT2DtHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "bf4fedbf-fe5d-4b0a-a38c-af3b9c145a98"
      },
      "cell_type": "code",
      "source": [
        "df2 = df[MAGIC_COLS]\n",
        "batches = []\n",
        "lags = []\n",
        "\n",
        "total = df2.shape[0]\n",
        "\n",
        "with tqdm(total=total) as pbar:\n",
        "  while len(df2.index) > 0:\n",
        "    pbar.update(total - len(df2.index) - pbar.n)    \n",
        "    batch, lag = find_ordered_index(df2, df2.index[0], max_period=37)\n",
        "    if len(batches) >= 3:\n",
        "      batches.append(batch)\n",
        "      lags.append(lag)\n",
        "    df2.drop(batch, inplace=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/49342 [00:00<?, ?it/s]/usr/local/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  errors=errors)\n",
            "100%|█████████▉| 49341/49342 [9:22:39<00:00,  1.46it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xOmKBz3Ck3m2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('test_row_batch.pkl', 'wb') as f:\n",
        "  pickle.dump([batches, lags], f)\n",
        "  \n",
        "!mkdir model\n",
        "!gsutil cp model/test_row_batch.pkl gs://{os.environ['GCP_BUCKET']}/model/test_row_batch.pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yBeKoj4c1rfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c288a04-a7da-4872-b0fd-5d52a8e2303a"
      },
      "cell_type": "code",
      "source": [
        "sum([len(batch) for batch in batches if len(batch) >= 3])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5390"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "j2lT2Xe9_G3_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "\n",
        "def pred(batch, lag):\n",
        "    batch_df = df.loc[batch][['target']+MAGIC_COLS]\n",
        "    new_batch = []\n",
        "    for i in range(len(lag)):\n",
        "      for j in range(lag[i]-1, 0, -1):\n",
        "        batch_df.loc[batch[i]+'_expand_%d'%j] = batch_df[MAGIC_COLS].loc[batch[i]].shift(-j).fillna(0.)\n",
        "        new_batch += [batch[i]+'_expand_%d'%j]\n",
        "      new_batch += [batch[i]]\n",
        "        \n",
        "    batch_df = batch_df.reindex(new_batch)\n",
        "    batch_df['pred'] = batch_df[MAGIC_COLS[0]].shift(-2).fillna(0.)\n",
        "    return batch_df.loc[batch][['target', 'pred']+MAGIC_COLS]\n",
        "\n",
        "  \n",
        "df['pred'] = pd.read_parquet()\n",
        "  \n",
        "for batch, lag in zip(batches, lags):\n",
        "    res = pred(batch, lag)\n",
        "    df.loc[res.index, 'pred'] = res['pred']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XEfsXPySkduB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['pred']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uis2f4vz2Lj1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}